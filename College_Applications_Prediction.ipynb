{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d912d22c",
   "metadata": {},
   "source": [
    "### In this exercise, we will predict the number of applications received using the other variables in the College data set in the ISLR2 package. ** be sure to look closely at this data, you may want to consider the multi-scale nature of the problem, and perhaps use a transformation on some of the variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "638a25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdb7fc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>777</li><li>18</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 777\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 777\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 777  18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ISLR2)\n",
    "data(College)\n",
    "#head(College)\n",
    "dim(College)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9721d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"caret\")\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dab5ca",
   "metadata": {},
   "source": [
    "#### 1. a) Split the data set into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02026c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 (a) Split the data set into a training set and a test set. \n",
    "\n",
    "set.seed(1)\n",
    "college_data <- College\n",
    "\n",
    "train_indis <- sample(1:nrow(college_data), size = round(2/3*nrow(college_data)), replace = FALSE )\n",
    "\n",
    "training_data <- college_data[train_indis,]\n",
    "test_data <- college_data[-train_indis,]\n",
    "\n",
    "y_true_train <- training_data$Apps\n",
    "y_true_test <- test_data$Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e8963",
   "metadata": {},
   "source": [
    "#### Fit a linear model using least squares on the training set, and report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa66299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Apps ~ ., data = training_data)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5858.9  -454.1    -3.1   346.8  7322.1 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -681.36179  523.92530  -1.300  0.19403    \n",
       "PrivateYes  -471.63266  168.93660  -2.792  0.00544 ** \n",
       "Accept         1.71602    0.04853  35.363  < 2e-16 ***\n",
       "Enroll        -0.99656    0.25372  -3.928 9.78e-05 ***\n",
       "Top10perc     56.15705    6.65558   8.438 3.51e-16 ***\n",
       "Top25perc    -16.87251    5.23835  -3.221  0.00136 ** \n",
       "F.Undergrad    0.02392    0.04498   0.532  0.59518    \n",
       "P.Undergrad    0.07129    0.03705   1.924  0.05489 .  \n",
       "Outstate      -0.09104    0.02233  -4.077 5.31e-05 ***\n",
       "Room.Board     0.18008    0.05844   3.081  0.00218 ** \n",
       "Books          0.38276    0.32701   1.170  0.24237    \n",
       "Personal      -0.01392    0.07506  -0.186  0.85290    \n",
       "PhD          -12.89843    5.70565  -2.261  0.02421 *  \n",
       "Terminal       1.65090    6.22623   0.265  0.79100    \n",
       "S.F.Ratio     21.34762   16.53234   1.291  0.19721    \n",
       "perc.alumni    2.27061    4.98581   0.455  0.64901    \n",
       "Expend         0.05969    0.01373   4.347 1.67e-05 ***\n",
       "Grad.Rate      7.15113    3.60847   1.982  0.04805 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1031 on 500 degrees of freedom\n",
       "Multiple R-squared:  0.9329,\tAdjusted R-squared:  0.9307 \n",
       "F-statistic: 409.1 on 17 and 500 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Residual sum of squares error : 14256206623.2306\"\n",
      "[1] \"Mean Squared error : 27521634.4077811\"\n"
     ]
    }
   ],
   "source": [
    "#Linear regression model \n",
    "linear_model <- lm(Apps ~ ., data = training_data)\n",
    "summary(linear_model)\n",
    "\n",
    "#Fitting trainning model on test set\n",
    "pred_linear <- predict(linear_model, new_data = test_data)\n",
    "\n",
    "#Test error\n",
    "test_err <- sum((y_true_test - pred_linear)^2) #sum of residual squares error\n",
    "mean_squared_err <- mean((y_true_test - pred_linear)^2) #mean squared error\n",
    "\n",
    "print(paste(\"Residual sum of squares error :\", test_err, sep = \" \"))\n",
    "print(paste(\"Mean Squared error :\", mean_squared_err, sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efa85a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"glmnet\")\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e8458",
   "metadata": {},
   "source": [
    "#### 1. b) Fit a ridge regression model on the training set, with λ chosen by crossvalidation. Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "375a81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Residual sum of squares error : 288284960.387111\"\n",
      "[1] \"Mean Squared error : 1113069.34512398\"\n"
     ]
    }
   ],
   "source": [
    "#Converting training and test data to matrix as cv.glment takes matrix as input\n",
    "x_train <- model.matrix(Apps~.,training_data)[,-1]\n",
    "x_test <- model.matrix(Apps~.,test_data)[,-1]\n",
    "\n",
    "\n",
    "#Choosing the tuning parameter using cross validation\n",
    "set.seed(2)\n",
    "cv_out_ridge <- cv.glmnet(x_train, y_true_train, alpha = 0)\n",
    "#plot(cv_out_ridge)\n",
    "bestlam_ridge <- cv_out_ridge$lambda.min\n",
    "\n",
    "\n",
    "#Ridge regression model \n",
    "ridge_model <- glmnet(x_train, y_true_train, alpha = 0, lambda = bestlam_ridge)\n",
    "#summary(ridge_model)\n",
    "\n",
    "\n",
    "#Fitting trainning model on test set\n",
    "pred_ridge <- predict(ridge_model, s = bestlam_ridge, newx = x_test)\n",
    "\n",
    "\n",
    "#Test error\n",
    "test_err_ridge <- sum((pred_ridge - y_true_test)^2)  #sum of residual squares error\n",
    "mean_squared_err_ridge <- mean((pred_ridge - y_true_test)^2) #mean squared error\n",
    "\n",
    "print(paste(\"Residual sum of squares error :\", test_err_ridge, sep = \" \"))\n",
    "print(paste(\"Mean Squared error :\", mean_squared_err_ridge, sep = \" \"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d9618",
   "metadata": {},
   "source": [
    "#### 1. d) Fit a lasso model on the training set, with λ chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781e0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Residual sum of squares error : 304910441.822123\"\n",
      "[1] \"Mean Squared error : 1177260.39313561\"\n",
      "[1] \"Non-zero coefficient estimates are :\"\n",
      "  (Intercept)    PrivateYes        Accept        Enroll     Top10perc \n",
      "-747.93075081 -409.30830511    1.63784037   -0.62491795   46.99407816 \n",
      "    Top25perc   P.Undergrad      Outstate    Room.Board         Books \n",
      " -10.41045253    0.05029946   -0.07347353    0.16322017    0.29906589 \n",
      "          PhD     S.F.Ratio        Expend \n",
      "  -9.87016666   14.78812206    0.05606723 \n"
     ]
    }
   ],
   "source": [
    "#Choosing the tuning parameter using cross validation\n",
    "set.seed(3)\n",
    "cv_out_lasso <- cv.glmnet(x_train, y_true_train, alpha = 1)\n",
    "#plot(cv_out_lasso)\n",
    "bestlam_lasso <- cv_out_lasso$lambda.min\n",
    "\n",
    "\n",
    "#Lasso model \n",
    "lasso_model <- glmnet(x_train, y_true_train, alpha = 1, lambda = bestlam_lasso)\n",
    "#summary(lasso_model)\n",
    "\n",
    "\n",
    "#Fitting trainning model on test set\n",
    "pred_lasso <- predict(lasso_model, s = bestlam_lasso, newx = x_test)\n",
    "\n",
    "\n",
    "#Test error\n",
    "test_err_lasso <- sum((pred_lasso - y_true_test)^2)  #sum of residual squares error\n",
    "mean_squared_lasso <- mean((pred_lasso - y_true_test)^2) #mean squared error\n",
    "\n",
    "print(paste(\"Residual sum of squares error :\", test_err_lasso, sep = \" \"))\n",
    "print(paste(\"Mean Squared error :\", mean_squared_lasso, sep = \" \"))\n",
    "\n",
    "#Lasso coefficients\n",
    "lasso_coef <- predict(lasso_model, type = \"coefficients\", s = bestlam_lasso)[1:length(lasso_model$beta),]\n",
    "#Non-zero coefficients\n",
    "nonzero_coef <- lasso_coef[lasso_coef!=0]\n",
    "print(\"Non-zero coefficient estimates are :\")\n",
    "print(nonzero_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84189617",
   "metadata": {},
   "source": [
    "#### 1. (g) Comment more generally on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these three approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06d541f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9219198\n"
     ]
    }
   ],
   "source": [
    "totalSumOFSquares = sum((mean(test_data$Apps) - test_data$Apps)^2)\n",
    "totalSumOfResidualSquares = sum((pred_ridge - test_data$Apps)^2)\n",
    "accuracy <- (1 - (totalSumOfResidualSquares)/(totalSumOFSquares))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ad3bf",
   "metadata": {},
   "source": [
    "**Yes, we can predict the number of college applications recieed with an accuracy of 92.19198%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "kernelspec"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
